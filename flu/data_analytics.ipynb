{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guess who got the shot\n",
    "\n",
    "Let's try to predict whether people got H1N1 and seasonal flu vaccines using information they shared about their backgrounds, opinions, and health behaviors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vaccine](COVID.jpg \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we're going to import some libraries. In the intro to programming class, the functions we used were very basic, and they were available by default. But python has a wide variety of uses, so there are thousands of additional libraries, some of which are built in to python, and some of which are external, which provide additional functionality.\n",
    "\n",
    "To use these libraries, we must first import them. For now we're mainly going to need pandas and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code will download the data we need. You don't need ot worry about this for now.\n",
    "!wget https://raw.githubusercontent.com/haritha-j/alchemize/main/flu/training_set_features.csv\n",
    "!wget https://raw.githubusercontent.com/haritha-j/alchemize/main/flu/training_set_labels.csv\n",
    "!wget https://raw.githubusercontent.com/haritha-j/alchemize/main/flu/test_set_featuress.csv\n",
    "!wget https://raw.githubusercontent.com/haritha-j/alchemize/main/flu/submission_format.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA DATA DATA\n",
    "\n",
    "We will be using 4 main files.\n",
    "\n",
    "**Training Features**: These are the input variables that your model will use to predict the probability that people received H1N1 flu and seasonal flu vaccines. There are 35 feature columns in total, each a response to a survey question. These questions cover several different topics, such as whether people observed safe behavioral practices, their opinions about the diseases and the vaccines, and their demographics. Check out the problem description page for more information.\n",
    "\n",
    "\n",
    "**Training Labels**: These are the labels corresponding to the observations in the training features. There are two target variables: h1n1_vaccine and seasonal_vaccine. Both are binary variables, with 1 indicating that a person received the respective flu vaccine and 0 indicating that a person did not receive the respective flu vaccine. Note that this is what is known as a \"multilabel\" modeling task.\n",
    "\n",
    "\n",
    "**Test Features**: These are the features for observations that you will use to generate the submission predictions after training a model. We don't give you the labels for these samples—it's up to you to generate them.\n",
    "\n",
    "\n",
    "**Submission Format**: This file serves as an example for how to format your submission. It contains the index and columns for our submission prediction. The two target variable columns are filled with 0.5 and 0.7 as an example. Your submission to the leaderboard must be in this exact format (with different prediction values) in order to be scored successfully!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data](data.jpg \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn a little about our data.\n",
    "\n",
    "The first column `respondent_id` is a unique and random identifier. The remaining 35 features are described below.\n",
    "\n",
    "For all binary variables: `0` = No; `1` = Yes.\n",
    "\n",
    "-   `h1n1_concern` - Level of concern about the H1N1 flu.\n",
    "    -   `0` = Not at all concerned; `1` = Not very concerned; `2` = Somewhat concerned; `3` = Very concerned.\n",
    "-   `h1n1_knowledge` - Level of knowledge about H1N1 flu.\n",
    "    -   `0` = No knowledge; `1` = A little knowledge; `2` = A lot of knowledge.\n",
    "-   `behavioral_antiviral_meds` - Has taken antiviral medications. (binary)\n",
    "-   `behavioral_avoidance` - Has avoided close contact with others with flu-like symptoms. (binary)\n",
    "-   `behavioral_face_mask` - Has bought a face mask. (binary)\n",
    "-   `behavioral_wash_hands` - Has frequently washed hands or used hand sanitizer. (binary)\n",
    "-   `behavioral_large_gatherings` - Has reduced time at large gatherings. (binary)\n",
    "-   `behavioral_outside_home` - Has reduced contact with people outside of own household. (binary)\n",
    "-   `behavioral_touch_face` - Has avoided touching eyes, nose, or mouth. (binary)\n",
    "-   `doctor_recc_h1n1` - H1N1 flu vaccine was recommended by doctor. (binary)\n",
    "-   `doctor_recc_seasonal` - Seasonal flu vaccine was recommended by doctor. (binary)\n",
    "-   `chronic_med_condition` - Has any of the following chronic medical conditions: asthma or an other lung condition, diabetes, a heart condition, a kidney condition, sickle cell anemia or other anemia, a neurological or neuromuscular condition, a liver condition, or a weakened immune system caused by a chronic illness or by medicines taken for a chronic illness. (binary)\n",
    "-   `child_under_6_months` - Has regular close contact with a child under the age of six months. (binary)\n",
    "-   `health_worker` - Is a healthcare worker. (binary)\n",
    "-   `health_insurance` - Has health insurance. (binary)\n",
    "-   `opinion_h1n1_vacc_effective` - Respondent's opinion about H1N1 vaccine effectiveness.\n",
    "    -   `1` = Not at all effective; `2` = Not very effective; `3` = Don't know; `4` = Somewhat effective; `5` = Very effective.\n",
    "-   `opinion_h1n1_risk` - Respondent's opinion about risk of getting sick with H1N1 flu without vaccine.\n",
    "    -   `1` = Very Low; `2` = Somewhat low; `3` = Don't know; `4` = Somewhat high; `5` = Very high.\n",
    "-   `opinion_h1n1_sick_from_vacc` - Respondent's worry of getting sick from taking H1N1 vaccine.\n",
    "    -   `1` = Not at all worried; `2` = Not very worried; `3` = Don't know; `4` = Somewhat worried; `5` = Very worried.\n",
    "-   `opinion_seas_vacc_effective` - Respondent's opinion about seasonal flu vaccine effectiveness.\n",
    "    -   `1` = Not at all effective; `2` = Not very effective; `3` = Don't know; `4` = Somewhat effective; `5` = Very effective.\n",
    "-   `opinion_seas_risk` - Respondent's opinion about risk of getting sick with seasonal flu without vaccine.\n",
    "    -   `1` = Very Low; `2` = Somewhat low; `3` = Don't know; `4` = Somewhat high; `5` = Very high.\n",
    "-   `opinion_seas_sick_from_vacc` - Respondent's worry of getting sick from taking seasonal flu vaccine.\n",
    "    -   `1` = Not at all worried; `2` = Not very worried; `3` = Don't know; `4` = Somewhat worried; `5` = Very worried.\n",
    "-   `age_group` - Age group of respondent.\n",
    "-   `education` - Self-reported education level.\n",
    "-   `race` - Race of respondent.\n",
    "-   `sex` - Sex of respondent.\n",
    "-   `income_poverty` - Household annual income of respondent with respect to 2008 Census poverty thresholds.\n",
    "-   `marital_status` - Marital status of respondent.\n",
    "-   `rent_or_own` - Housing situation of respondent.\n",
    "-   `employment_status` - Employment status of respondent.\n",
    "-   `hhs_geo_region` - Respondent's residence using a 10-region geographic classification defined by the U.S. Dept. of Health and Human Services. Values are represented as short random character strings.\n",
    "-   `census_msa` - Respondent's residence within metropolitan statistical areas (MSA) as defined by the U.S. Census.\n",
    "-   `household_adults` - Number of *other* adults in household, top-coded to 3.\n",
    "-   `household_children` - Number of children in household, top-coded to 3.\n",
    "-   `employment_industry` - Type of industry respondent is employed in. Values are represented as short random character strings.\n",
    "-   `employment_occupation` - Type of occupation of respondent. Values are represented as short random character strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to load our data. This should be a little familiar to you if you went through the additional exercise you were given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"training_set_features.csv\", index_col=\"respondent_id\")\n",
    "labels_df = pd.read_csv(\"training_set_labels.csv\", index_col=\"respondent_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"features_df.shape\", features_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"labels_df.shape\", labels_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZE VISUALIZE \n",
    "\n",
    "Before we do anything with our data, we need to get familiar with it. The best way to do this is to visualize our data.\n",
    "\n",
    "We're going to need one extra libary for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "n_obs = labels_df.shape[0]\n",
    "\n",
    "(labels_df['h1n1_vaccine']\n",
    "    .value_counts()\n",
    "    .div(n_obs)\n",
    "    .plot.barh(title=\"Proportion of H1N1 Vaccine\", ax=ax[0])\n",
    ")\n",
    "ax[0].set_ylabel(\"h1n1_vaccine\")\n",
    "\n",
    "(labels_df['seasonal_vaccine']\n",
    "    .value_counts()\n",
    "    .div(n_obs)\n",
    "    .plot.barh(title=\"Proportion of Seasonal Vaccine\", ax=ax[1])\n",
    ")\n",
    "ax[1].set_ylabel(\"seasonal_vaccine\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![anti](anti.jpg \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like roughy half of people received the seasonal flu vaccine, but only about 20% of people received the H1N1 flu vaccine. In terms of class balance, we say that the seasonal flu vaccine target has balanced classes, but the H1N1 flu vaccine target has moderately imbalanced classes.\n",
    "\n",
    "Are the two target variables independent? Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    labels_df[\"h1n1_vaccine\"], \n",
    "    labels_df[\"seasonal_vaccine\"], \n",
    "    margins=True,\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure Pearson correlation for two binary variables\n",
    "(labels_df[\"h1n1_vaccine\"]\n",
    "     .corr(labels_df[\"seasonal_vaccine\"], method=\"pearson\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two variables have a phi coefficient of 0.37, indicating a moderate positive correlation. We can see that in the cross-tabulation as well. Most people who got an H1N1 flu vaccine also got the seasonal flu vaccine. While a minority of people who got the seasonal vaccine got the H1N1 vaccine, they got the H1N1 vaccine at a higher rate than those who did not get the seasonal vaccine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "Next, let's take a look at our features. From the problem description page, we know that the feature variables are almost all categorical: a mix of binary, ordinal, and nominal features. Let's pick a few and see how the rates of vaccination may differ across the levels of the feature variables.\n",
    "\n",
    "First, let's combine our features and labels into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = features_df.join(labels_df)\n",
    "print(joined_df.shape)\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "Next, let's see how the features are correlated with the target variables. We'll start with trying to visualize if there is simple bivariate correlation. If a feature is correlated with the target, we'd expect there to be different patterns of vaccination as you vary the values of the feature.\n",
    "\n",
    "Jumping right to the right final visualization is hard. We can instead pick one feature and one target and work our way up to a prototype, before applying it to more features and both targets. We'll use h1n1_concern, the level of concern the person showed about the H1N1 flu, and h1n1_vaccine as a target variable.\n",
    "\n",
    "First, we'll get the count of observations for each combination of those two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![charts](charts.png \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = (joined_df[['h1n1_concern', 'h1n1_vaccine']]\n",
    "              .groupby(['h1n1_concern', 'h1n1_vaccine'])\n",
    "              .size()\n",
    "              .unstack('h1n1_vaccine')\n",
    "         )\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = counts.plot.barh()\n",
    "ax.invert_yaxis()\n",
    "ax.legend(\n",
    "    loc='center right', \n",
    "    bbox_to_anchor=(1.3, 0.5), \n",
    "    title='h1n1_vaccine'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's wrong with this picture?\n",
    "\n",
    "\n",
    "\n",
    "Let's try something a little different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_concern_counts = counts.sum(axis='columns')\n",
    "h1n1_concern_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = counts.div(h1n1_concern_counts, axis='index')\n",
    "props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = props.plot.barh()\n",
    "ax.invert_yaxis()\n",
    "ax.legend(\n",
    "    loc='center left', \n",
    "    bbox_to_anchor=(1.05, 0.5),\n",
    "    title='h1n1_vaccine'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a clearer picture of what's happening! In this plot, each pair of blue (no vaccine) and orange (received vaccine) bars add up to 1.0. We can clearly see that even though most people don't get the H1N1 vaccine, they are more likely to if they have a higher level of concern. It looks like h1n1_concern will be a useful feature when we get to modeling.\n",
    "\n",
    "Since every pair of bars adds up to 1.0 and we only have two bars, this is actually a good use case for a stacked bar chart, to make it even easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = props.plot.barh(stacked=True)\n",
    "ax.invert_yaxis()\n",
    "ax.legend(\n",
    "    loc='center left', \n",
    "    bbox_to_anchor=(1.05, 0.5),\n",
    "    title='h1n1_vaccine'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to functions\n",
    "\n",
    "Remember how we learnt that we can define our own functions so that we won't have to keep writing the same function over and over?\n",
    "Let's make one to visualize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vaccination_rate_plot(col, target, data, ax=None):\n",
    "    \"\"\"Stacked bar chart of vaccination rate for `target` against \n",
    "    `col`. \n",
    "    \n",
    "    Args:\n",
    "        col (string): column name of feature variable\n",
    "        target (string): column name of target variable\n",
    "        data (pandas DataFrame): dataframe that contains columns \n",
    "            `col` and `target`\n",
    "        ax (matplotlib axes object, optional): matplotlib axes \n",
    "            object to attach plot to\n",
    "    \"\"\"\n",
    "    counts = (joined_df[[target, col]]\n",
    "                  .groupby([target, col])\n",
    "                  .size()\n",
    "                  .unstack(target)\n",
    "             )\n",
    "    group_counts = counts.sum(axis='columns')\n",
    "    props = counts.div(group_counts, axis='index')\n",
    "\n",
    "    props.plot(kind=\"barh\", stacked=True, ax=ax)\n",
    "    ax.invert_yaxis()\n",
    "    ax.legend().remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn \n",
    "use this funtion to draw some graphs, and discover some trends!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'h1n1_concern'\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    1, 2, figsize=(9, 2.5)\n",
    ")\n",
    "vaccination_rate_plot(\n",
    "    column, 'h1n1_vaccine', joined_df, ax=ax[0]\n",
    ")\n",
    "vaccination_rate_plot(\n",
    "    column, 'seasonal_vaccine', joined_df, ax=ax[1]\n",
    ")\n",
    "\n",
    "ax[0].legend(\n",
    "    loc='lower center', bbox_to_anchor=(0.5, 1.05), title='h1n1_vaccine'\n",
    ")\n",
    "ax[1].legend(\n",
    "    loc='lower center', bbox_to_anchor=(0.5, 1.05), title='seasonal_vaccine'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use this function to plot a whole bunch of charts together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_plot = [\n",
    "    'h1n1_concern',\n",
    "    'h1n1_knowledge',\n",
    "    'opinion_h1n1_vacc_effective',\n",
    "    'opinion_h1n1_risk',\n",
    "    'opinion_h1n1_sick_from_vacc',\n",
    "    'opinion_seas_vacc_effective',\n",
    "    'opinion_seas_risk',\n",
    "    'opinion_seas_sick_from_vacc',\n",
    "    'sex',\n",
    "    'age_group',\n",
    "    'race',\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    len(cols_to_plot), 2, figsize=(9,len(cols_to_plot)*2.5)\n",
    ")\n",
    "for idx, col in enumerate(cols_to_plot):\n",
    "    vaccination_rate_plot(\n",
    "        col, 'h1n1_vaccine', joined_df, ax=ax[idx, 0]\n",
    "    )\n",
    "    vaccination_rate_plot(\n",
    "        col, 'seasonal_vaccine', joined_df, ax=ax[idx, 1]\n",
    "    )\n",
    "    \n",
    "ax[0, 0].legend(\n",
    "    loc='lower center', bbox_to_anchor=(0.5, 1.05), title='h1n1_vaccine'\n",
    ")\n",
    "ax[0, 1].legend(\n",
    "    loc='lower center', bbox_to_anchor=(0.5, 1.05), title='seasonal_vaccine'\n",
    ")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the knowledge and opinion questions have pretty strong signal for both target variables.\n",
    "\n",
    "The demographic features have stronger correlation with seasonal_vaccine, but much less so far h1n1_vaccine. In particular, we interestingly see a strong correlation with age_group with the seasonal_vaccine but not with h1n1_vaccine. It appears that with seasonal flu, people act appropriately according to the fact that people more impacted and have higher risk of flu-related complications with age. It turns out though that H1N1 flu has an interesting relationship with age: even though older people have higher risk of complications, they were less likely to get infected! While we know anything about causality from this analysis, it seems like the risk factors ended up being reflected in the vaccination rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "We will be using logistic regression, a simple and fast linear model for classification problems. Logistic regression is a great model choice for a first-pass baseline model when starting out on a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO\n",
    "### Primer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're gonna need some additional imports here, from a library called scikit learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "RANDOM_SEED = 6    # Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using scikit-learn's logistic regression implementation.\n",
    "\n",
    "Standard logistic regression only works with numeric input for features. Since this is a benchmark, we're going to build simple models only using the numeric columns of our dataset.\n",
    "\n",
    "Categorical variables with non-numeric values take a little more preprocessing to prepare for many machine learning algorithms. We're not going to deal with them in this benchmark walkthrough, but there are many different ways to encode categorical variables into numeric values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.dtypes != \"object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = features_df.columns[features_df.dtypes != \"object\"].values\n",
    "print(numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing features\n",
    " \n",
    "Preprocessing is one of the key aspects of data analyiss, and typically data analysts spend a lot of time on this step,\n",
    "\n",
    "Data often comes with many missing values, errors and other issues that needs to be fixed before anything useful can be inferred from the data.\n",
    "\n",
    "For this intro, we will only be focus on a couple of very common preprocessing techniques.\n",
    "\n",
    "**Scaling:** Transform all features to be on the same scale. This matters when using regularization, which we will discuss in the next section. We will use StandardScaler, also known as Z-score scaling. This scales and shifts features so that they have zero mean and unit variance.\n",
    "\n",
    "**NA Imputation:** Logistic regression does not handle NA values. We will use median imputation, which fills missing values with the median from the training data, implemented with SimpleImputer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![clean](clean.jpg \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start using Scikit-Learn's built-in composition functionality to encapsulate everything into a pipeline. Building pipelines is a best practice for building machine learning models. Among other benefits, it makes it easy to reuse on new data (such as our test data). The great thing about pipelines is that they have the same interface as transformers and estimators, so you can treat them as if they are.\n",
    "\n",
    "In the block below, we're going to first chain together the preprocessing steps (scaling and imputing) into one intermediate pipeline object numeric_preprocessing_steps. Then, we use that with Scikit-Learn's ColumnTransformer, which is a convenient way to grab columns out of a pandas data frame and then apply a specified transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain preprocessing into a Pipeline object\n",
    "# each step is a tuple of (name you chose, sklearn transformer)\n",
    "numeric_preprocessing_steps = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('simple_imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "# create the preprocessor stage of final pipeline\n",
    "# each entry in the transformer list is a tuple of\n",
    "# (name you choose, sklearn transformer, list of columns)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"numeric\", numeric_preprocessing_steps, numeric_cols)\n",
    "    ],\n",
    "    remainder = \"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get to the good stuff\n",
    "\n",
    "Now we're finally getting close to what we set out to do : predicting values.\n",
    "\n",
    "We'll use scikit-learn's default hyperparameters (hyper what now?) for LogisticRegression of L2 (a.k.a. Ridge) regularization with C value (inverse regularization strength) of 1. Regularization is useful because it reduces overfitting.\n",
    "\n",
    "\n",
    "\n",
    "Because we have two labels we need to predict, we can use Scikit-Learn's MultiOutputClassifier. This is a convenient shortcut for training two of the same type of model and having them run together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = MultiOutputClassifier(\n",
    "    estimator=LogisticRegression(penalty=\"l2\", C=1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets combine the preprocessing and the classifier.\n",
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", estimators),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at what we've built\n",
    "full_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "![test](train.jpg \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
